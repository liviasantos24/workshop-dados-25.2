#  Projeto de Machine Learning ‚Äì Previs√£o de Sobreviv√™ncia em One Piece (Fict√≠cio)

##  Objetivo
Criar um modelo de **classifica√ß√£o bin√°ria** para prever se um personagem de **One Piece** sobreviver√° a uma batalha com base em caracter√≠sticas como for√ßa, intelig√™ncia, velocidade, tipo de fruta do diabo e habilidades especiais.

---

##  Estrutura do Projeto

### 1. Abordar o problema e analisar
- **Problema:** Prever se um personagem sobrevive a uma batalha.  
- **Tipo:** Classifica√ß√£o bin√°ria (0 = n√£o sobrevive, 1 = sobrevive).  
- **Desafios:**
  - Dataset fict√≠cio e pequeno;
  - Vari√°veis categ√≥ricas (tipo de fruta, habilidades especiais);
  - Diferentes n√≠veis de for√ßa, intelig√™ncia e velocidade.

---

### 2. Obter os dados
- **Fonte:** dataset fict√≠cio criado diretamente em Python com `pandas`.  
- **Colunas:**  
  - `Nome`  
  - `Forca`  
  - `Inteligencia`  
  - `Velocidade`  
  - `Tipo_Fruta`  
  - `Habilidade`  
  - `Sobrevive` (vari√°vel alvo: 1 = sobrevive, 0 = n√£o sobrevive)  

Exemplo inicial do dataset:

| Nome   | Forca | Inteligencia | Velocidade | Tipo_Fruta | Habilidade | Sobrevive |
|--------|-------|--------------|------------|------------|------------|-----------|
| Luffy  | 95    | 70           | 90         | GomuGomu   | Haki       | 1         |
| Zoro   | 90    | 65           | 85         | Nenhuma    | Haki       | 1         |
| Usopp  | 50    | 60           | 60         | Nenhuma    | Armadilha  | 0         |

---

### 3. Explorar os dados
- Verifica√ß√£o do tamanho (`df.shape`) e tipos (`df.info()`)  
- Estat√≠sticas descritivas (`df.describe()`)  
- Frequ√™ncia de tipos de fruta e habilidades (`value_counts()`)  
- Distribui√ß√£o da vari√°vel alvo (`df['Sobrevive'].value_counts()`)  

---

### 4. Tratamento dos dados
- Separa√ß√£o de vari√°veis num√©ricas (`Forca, Inteligencia, Velocidade`) e categ√≥ricas (`Tipo_Fruta, Habilidade`).  
- Pr√©-processamento:
  - Num√©ricos ‚Üí imputa√ß√£o com mediana + padroniza√ß√£o (`StandardScaler`).  
  - Categ√≥ricos ‚Üí imputa√ß√£o com valor mais frequente + one-hot encoding.  
- Implementado com `ColumnTransformer` e `Pipeline`.

---

### 5. Separar Base em Arrays
```python
X = df[["Forca", "Inteligencia", "Velocidade", "Tipo_Fruta", "Habilidade"]]
y = df["Sobrevive"]
```

---

### 6. Divis√£o Treino/Teste
-Separa√ß√£o em treino (70%) e teste (30%) estratificando pelo target:
from sklearn.model_selection import train_test_split
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)
```
---

### 7. Defini√ß√£o de Modelos
- Foram treinados 3 modelos do scikit-learn:
  - Logistic Regression (LogisticRegression(max_iter=500))
  - Random Forest (RandomForestClassifier(n_estimators=200, max_depth=5))
  - KNN (KNeighborsClassifier(n_neighbors=3))
-Cada modelo foi integrado a um pipeline com pr√©-processamento.

---

### 8. Defini√ß√£o de Modelos
Foram treinados 3 modelos do scikit-learn:

- **Logistic Regression**
- **Random Forest**
- **KNN**

Cada modelo foi integrado a um pipeline com pr√©-processamento.

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

modelos = {
    "Logistic Regression": LogisticRegression(max_iter=500),
    "Random Forest": RandomForestClassifier(n_estimators=200, max_depth=5),
    "KNN": KNeighborsClassifier(n_neighbors=3)
}
```

---

### 9. Valida√ß√£o dos Modelos
M√©tricas utilizadas: **Acur√°cia, Precision, Recall e F1-score**.  
Foi feita **valida√ß√£o cruzada com 5 folds estratificados (cross_val_score)**.  
Os resultados de treino/teste e da valida√ß√£o cruzada foram comparados.

```python
from sklearn.model_selection import cross_val_score

for nome, modelo in modelos.items():
    scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring="accuracy")
    print(f"{nome} - Acur√°cia M√©dia (CV): {scores.mean():.2f}")
```

---

### 10. Resultados e Uso
- O **RandomForestClassifier** apresentou o melhor desempenho (~83% de acur√°cia m√©dia).  
- O modelo final foi salvo como **onepiece_survival_model.pkl**.  

```python
import joblib

best_model = RandomForestClassifier(n_estimators=200, max_depth=5)
best_model.fit(X_train, y_train)
joblib.dump(best_model, "onepiece_survival_model.pkl")
```

Como usar o modelo salvo:

```python
# Carregar modelo treinado
modelo_carregado = joblib.load("onepiece_survival_model.pkl")

# Fazer previs√µes em novos personagens
previsoes = modelo_carregado.predict(X_test)
```
---

###  Resumo
Este projeto mostra o ciclo completo de **Machine Learning supervisionado**: desde a an√°lise e limpeza dos dados at√© o treinamento, avalia√ß√£o e salvamento do modelo final.  

O dataset fict√≠cio foi inspirado no universo de **One Piece**, com atributos como for√ßa, intelig√™ncia, velocidade, tipo de fruta e habilidades especiais.  
O objetivo foi prever se um personagem **sobrevive** ou n√£o em batalhas, com base nessas caracter√≠sticas.  

- O problema foi tratado como uma **classifica√ß√£o bin√°ria** (0 = n√£o sobrevive, 1 = sobrevive).  
- Foram utilizados diferentes modelos de classifica√ß√£o: **Logistic Regression, KNN e Random Forest**.  
- O modelo que apresentou melhor desempenho foi o **Random Forest**, alcan√ßando cerca de **83% de acur√°cia m√©dia**.  
- O modelo final foi salvo em `onepiece_survival_model.pkl` para uso posterior.  

Este projeto fict√≠cio ilustra como aplicar **t√©cnicas de pr√©-processamento, treino, valida√ß√£o e salvamento de modelos** em um caso divertido baseado em One Piece. ‚öîÔ∏èüè¥‚Äç‚ò†Ô∏è



